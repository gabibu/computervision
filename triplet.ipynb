{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9GFKlFRwLVr",
        "outputId": "9735f4c6-73d9-4d8d-c947-5fb30e71c9cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision import transforms, datasets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q drive/MyDrive/DS_dataset.zip"
      ],
      "metadata": {
        "id": "aPCnmaobwTob"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'train'\n",
        "test_dir = 'test'"
      ],
      "metadata": {
        "id": "NV1ZypABwdZe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_paths = []\n",
        "for label in os.listdir(test_dir):\n",
        "  label_path = os.path.join(test_dir, label)\n",
        "\n",
        "  test_images_path = [(label, os.path.join(label_path, image)) for image in os.listdir(label_path)]\n",
        "  test_paths.extend(test_images_path)\n",
        "\n",
        "test_df = pd.DataFrame(test_paths, columns = ['label', 'path']).sample(frac = 1.)\n",
        "len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AcrnPMmrWni",
        "outputId": "0ba35e40-743e-45e3-da1a-3f31abb3b5f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_paths = [(os.path.join(train_dir, file),) for file in os.listdir(train_dir)]\n",
        "train_df = pd.DataFrame(train_images_paths, columns = ['path']).sample(frac = 1.)\n",
        "len(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0pcSzDHy7Yo",
        "outputId": "98369e8e-a281-4c88-96e1-3485cd85e37e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2669"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, df, anchor_transforms, other_transforms):\n",
        "        self._df = df\n",
        "        self._anchor_transforms = anchor_transforms\n",
        "        self._other_transforms = other_transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      row = self._df.iloc[idx]\n",
        "      base_image_path = row['path']\n",
        "\n",
        "      while True:\n",
        "\n",
        "        other_image_path = self._df.sample(1).iloc[0]['path']\n",
        "        if other_image_path != base_image_path:\n",
        "          break\n",
        "\n",
        "      base_image = Image.open(base_image_path).convert('RGB')\n",
        "      other_image = Image.open(other_image_path).convert('RGB')\n",
        "      anchor = self._anchor_transforms(base_image)\n",
        "      negative = self._anchor_transforms(other_image)\n",
        "      positive = self._other_transforms(base_image)\n",
        "\n",
        "      return anchor, positive, negative\n",
        "\n",
        "\n",
        "class TestDatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, df, transforms):\n",
        "        self._df = df\n",
        "        self._transforms = transforms\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      row = self._df.iloc[idx]\n",
        "\n",
        "      base_image_path = row['path']\n",
        "      label = row['label']\n",
        "\n",
        "\n",
        "      base_image = Image.open(base_image_path).convert('RGB')\n",
        "      positive = self._transforms(base_image)\n",
        "\n",
        "      return positive, label"
      ],
      "metadata": {
        "id": "sYke81mjzuJ7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_and_std(dataloader):\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for (_,data, _) in dataloader:\n",
        "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
        "        num_batches += 1\n",
        "\n",
        "    mean = channels_sum / num_batches\n",
        "\n",
        "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "basic_transformations1 = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "temp_dataset = DatasetLoader(train_df, basic_transformations1, basic_transformations1)\n",
        "temp_dataloader = DataLoader(dataset=temp_dataset, batch_size=64)\n",
        "\n",
        "means, stds = get_mean_and_std(temp_dataloader)\n",
        "means, stds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h28BOS931TwF",
        "outputId": "99769b81-5d0b-48ae-d10b-b63b15b43979"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.4609, 0.4236, 0.3002]), tensor([0.2937, 0.2635, 0.2859]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 32\n",
        "crop_size = 32"
      ],
      "metadata": {
        "id": "S8qbhd-1yefZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_transformations = transforms.Compose([\n",
        "    transforms.Resize(size=(image_size,image_size)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "9xQ3Gb4uam3X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0vaaVkE9TaUG",
        "outputId": "52fffa68-1254-4cd4-94b5-a321abb1f8f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(6)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=2, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(2)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.fc1 = nn.Linear(450, 50)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.relu(self.bn1(self.conv1(input)))\n",
        "        output = F.relu(self.bn2(self.conv2(output)))\n",
        "        output = self.pool(output)\n",
        "        output = output.view(output.shape[0], -1)\n",
        "        output = self.fc1(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def initialize_weights(m):\n",
        "  if isinstance(m, nn.Conv2d):\n",
        "      nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
        "      if m.bias is not None:\n",
        "          nn.init.constant_(m.bias.data, 0)\n",
        "  elif isinstance(m, nn.BatchNorm2d):\n",
        "      nn.init.constant_(m.weight.data, 1)\n",
        "      nn.init.constant_(m.bias.data, 0)\n",
        "  elif isinstance(m, nn.Linear):\n",
        "      nn.init.kaiming_uniform_(m.weight.data)\n",
        "      nn.init.constant_(m.bias.data, 0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKAABN83Kg5J",
        "outputId": "38b91aa7-235b-4d0f-ebcf-fb8619d51bcb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ou', torch.Size([2, 50]), torch.Size([2, 3, 32, 32]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "learning_rate = 0.001\n",
        "model = Network()\n",
        "model.apply(initialize_weights)\n",
        "model = model.to(device)\n",
        "\n",
        "advance_transformions = transforms.Compose([\n",
        "    transforms.Resize((image_size,image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomApply([transforms.ColorJitter(hue=.5, saturation=.3)], 0.5),\n",
        "\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomApply([transforms.RandomRotation(degrees=(0, 180))], 0.3),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))], 0.4),\n",
        "    transforms.RandomErasing(p=0.2)\n",
        "\n",
        "])\n",
        "\n",
        "basic_transformations = transforms.Compose([\n",
        "    transforms.Resize(size=(image_size,image_size)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "dataset = DatasetLoader(train_df, advance_transformions, basic_transformations)\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=64, shuffle = True)\n",
        "\n",
        "loss_func = (\n",
        "    nn.TripletMarginWithDistanceLoss(\n",
        "        distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cHrd0eVuXOzz",
        "outputId": "772bd8ef-f78b-4509-a5f6-58ad8699cea6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "anchors, positives, negatives  = next(iter(dataloader))\n"
      ],
      "metadata": {
        "id": "xfQEGOilgxgB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(anchors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "fmqdqLf9g4tZ",
        "outputId": "175801ee-9e02-44c4-fdf5-583180248591"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F4291ADCA60>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(positives[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "tcQgnUqKht33",
        "outputId": "94b07f50-86f7-4be6-c338-dd4d2094cae1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F42924A4970>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(negatives[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "TLtyCdQIhwD4",
        "outputId": "a6e83754-ef3d-487d-c5d7-386425bb8846"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F4291ADF9D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "model.train()\n",
        "\n",
        "for  epoch in range(num_epochs):\n",
        "  running_loss = []\n",
        "\n",
        "  for (anchor_img, positive_img, negative_img) in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "\n",
        "    anchor_img = anchor_img.to(device)\n",
        "    positive_img = positive_img.to(device)\n",
        "    negative_img = negative_img.to(device)\n",
        "\n",
        "\n",
        "\n",
        "    anchor_out = model(anchor_img)\n",
        "    positive_out = model(positive_img)\n",
        "    negative_out = model(negative_img)\n",
        "\n",
        "    loss = loss_func(anchor_out, positive_out, negative_out)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss.append(loss.cpu().detach().numpy())\n",
        "\n",
        "  print((epoch, np.mean(running_loss)))"
      ],
      "metadata": {
        "id": "uw9lKGE6MOh_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loader = TestDatasetLoader(test_df, basic_transformations)\n",
        "test_dataloader = DataLoader(dataset=test_data_loader, batch_size=128)\n",
        "model.eval()\n",
        "test_res = []\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for (images, labels) in tqdm(test_dataloader, desc=\"test\", leave=False):\n",
        "    images = images.to(device)\n",
        "    images_out = model(images).detach().cpu().numpy()\n",
        "\n",
        "    for i in range(images_out.shape[0]):\n",
        "      v = images_out[i]\n",
        "      l = labels[i]\n",
        "      test_res.append((v, l))\n",
        "\n",
        "test_res_df = pd.DataFrame(test_res, columns = ['vector', 'label'])\n",
        "len(test_res_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V0NKIhsFnw7",
        "outputId": "3fc2627b-3787-47ed-fde6-77dbc18ac891"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "df_cosine=pd.DataFrame(cosine_similarity(test_res_df['vector'].tolist(),dense_output=True))\n",
        "df_cosine['label'] = test_res_df['label']\n",
        "features = df_cosine.drop(columns = ['label'])\n",
        "\n",
        "kmeans = KMeans(\n",
        "    init=\"k-means++\",\n",
        "    n_clusters=5\n",
        ")\n",
        "\n",
        "kmeans.fit(features)\n",
        "\n",
        "clusters = kmeans.predict(features)\n",
        "\n",
        "test_res_df['cluster'] = clusters"
      ],
      "metadata": {
        "id": "_AUP5YLzc6oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res_df.groupby(['label', 'cluster']).size().to_frame('size').reset_index().sort_values(by = ['label', 'cluster'])"
      ],
      "metadata": {
        "id": "weTtcXI6UUDn"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}